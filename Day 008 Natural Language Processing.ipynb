{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing\n",
    "\n",
    "Prefer TSV files as we might have comma in the text itself, so CSV format will make it difficult only.\n",
    "\n",
    "In this we will be working on a data based on reviews given to a restuarant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the dataset\n",
    "dataset = pd.read_csv('data/Restaurant_Reviews.tsv', delimiter = '\\t', quoting = 3) #quoting = 3 means no quotes at all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Liked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stopped by during the late May bank holiday of...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The selection on the menu was great and so wer...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Liked\n",
       "0                           Wow... Loved this place.      1\n",
       "1                                 Crust is not good.      0\n",
       "2          Not tasty and the texture was just nasty.      0\n",
       "3  Stopped by during the late May bank holiday of...      1\n",
       "4  The selection on the menu was great and so wer...      1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the texts\n",
    "\n",
    "Apply stemming, do lemmatization, remove stopwords and punctuation.\n",
    "\n",
    "At last do Bag of Word model and tokenization..\n",
    "\n",
    "Cleaning the first review at 0th index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Wow... Loved this place.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['Review'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keep only letters in our review\n",
    "review = re.sub('[^a-zA-Z]', ' ', dataset['Review'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Wow    Loved this place '"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now check the first review\n",
    "review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change the review in lower case\n",
    "review = review.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wow    loved this place '"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/ankitsharma/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove the non-significant words.. (Stopwords)\n",
    "#import the nltk library\n",
    "import nltk\n",
    "nltk.download('stopwords') #download stopwords list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#traverse through the review and remove the irrelevant words\n",
    "review = review.split() #to change the from the string to the list format so that we can traverse.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wow', 'loved', 'this', 'place']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "review = [word for word in review if not word in stopwords.words('english')] #use set for using more words.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mType:\u001b[0m        list\n",
       "\u001b[0;31mString form:\u001b[0m ['wow', 'loved', 'place']\n",
       "\u001b[0;31mLength:\u001b[0m      3\n",
       "\u001b[0;31mDocstring:\u001b[0m  \n",
       "list() -> new empty list\n",
       "list(iterable) -> new list initialized from iterable's items\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "review?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming\n",
    "\n",
    "Going back to the root(stem) of the word. \n",
    "\n",
    "Loved --> Love\n",
    "\n",
    "Amusing --> Amus\n",
    "\n",
    "Wolves --> Wolv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "ps = PorterStemmer()\n",
    "\n",
    "review = [ps.stem(word) for word in review if not word in set(stopwords.words('english'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mType:\u001b[0m        list\n",
       "\u001b[0;31mString form:\u001b[0m ['wow', 'love', 'place']\n",
       "\u001b[0;31mLength:\u001b[0m      3\n",
       "\u001b[0;31mDocstring:\u001b[0m  \n",
       "list() -> new empty list\n",
       "list(iterable) -> new list initialized from iterable's items\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "review?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Joining the words together separated by space\n",
    "\n",
    "review = ' '.join(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mType:\u001b[0m        str\n",
       "\u001b[0;31mString form:\u001b[0m wow love place\n",
       "\u001b[0;31mLength:\u001b[0m      14\n",
       "\u001b[0;31mDocstring:\u001b[0m  \n",
       "str(object='') -> str\n",
       "str(bytes_or_buffer[, encoding[, errors]]) -> str\n",
       "\n",
       "Create a new string object from the given object. If encoding or\n",
       "errors is specified, then the object must expose a data buffer\n",
       "that will be decoded using the given encoding and error handler.\n",
       "Otherwise, returns the result of object.__str__() (if defined)\n",
       "or repr(object).\n",
       "encoding defaults to sys.getdefaultencoding().\n",
       "errors defaults to 'strict'.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "review?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Our dataset is of 1000 rows i.e. we have 1000 different reviews. \n",
    "* We need to change the scope of our loop to cover all the dataset and perform the cleaning process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will create a new list (a collection of text)\n",
    "corpus = []\n",
    "\n",
    "\n",
    "#Cleaning process for all the dataset\n",
    "for i in range(0, 1000):\n",
    "    review = re.sub('[^a-zA-Z]', ' ', dataset['Review'][i])\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    ps = PorterStemmer()\n",
    "    review = [ps.stem(word) for word in review if not word in set(stopwords.words('english'))]\n",
    "    review = ' '.join(review)\n",
    "    \n",
    "    corpus.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mType:\u001b[0m        list\n",
       "\u001b[0;31mString form:\u001b[0m ['wow love place', 'crust good', 'tasti textur nasti', 'stop late may bank holiday rick steve rec <...> m think go ninja sushi next time', 'wast enough life pour salt wound draw time took bring check']\n",
       "\u001b[0;31mLength:\u001b[0m      1000\n",
       "\u001b[0;31mDocstring:\u001b[0m  \n",
       "list() -> new empty list\n",
       "list(iterable) -> new list initialized from iterable's items\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "corpus?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Bag of Words..\n",
    "\n",
    "All the relevant words which are actually helpful in making this analyzer for a single time. Removing the unnecessary and repeated words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(max_features= 1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = cv.fit_transform(corpus).toarray() #created a sparse matrix for all the words in the review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mType:\u001b[0m            ndarray\n",
       "\u001b[0;31mString form:\u001b[0m    \n",
       "[[0 0 0 ... 0 0 0]\n",
       " [0 0 0 ... 0 0 0]\n",
       " [0 0 0 ... 0 0 0]\n",
       " ...\n",
       " [0 0 0 ... 0 0 0]\n",
       " [0 0 0 ... 0 0 0]\n",
       " [0 0 0 ... 0 0 0]]\n",
       "\u001b[0;31mLength:\u001b[0m          1000\n",
       "\u001b[0;31mFile:\u001b[0m            /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/numpy/__init__.py\n",
       "\u001b[0;31mDocstring:\u001b[0m       <no docstring>\n",
       "\u001b[0;31mClass docstring:\u001b[0m\n",
       "ndarray(shape, dtype=float, buffer=None, offset=0,\n",
       "        strides=None, order=None)\n",
       "\n",
       "An array object represents a multidimensional, homogeneous array\n",
       "of fixed-size items.  An associated data-type object describes the\n",
       "format of each element in the array (its byte-order, how many bytes it\n",
       "occupies in memory, whether it is an integer, a floating point number,\n",
       "or something else, etc.)\n",
       "\n",
       "Arrays should be constructed using `array`, `zeros` or `empty` (refer\n",
       "to the See Also section below).  The parameters given here refer to\n",
       "a low-level method (`ndarray(...)`) for instantiating an array.\n",
       "\n",
       "For more information, refer to the `numpy` module and examine the\n",
       "methods and attributes of an array.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "(for the __new__ method; see Notes below)\n",
       "\n",
       "shape : tuple of ints\n",
       "    Shape of created array.\n",
       "dtype : data-type, optional\n",
       "    Any object that can be interpreted as a numpy data type.\n",
       "buffer : object exposing buffer interface, optional\n",
       "    Used to fill the array with data.\n",
       "offset : int, optional\n",
       "    Offset of array data in buffer.\n",
       "strides : tuple of ints, optional\n",
       "    Strides of data in memory.\n",
       "order : {'C', 'F'}, optional\n",
       "    Row-major (C-style) or column-major (Fortran-style) order.\n",
       "\n",
       "Attributes\n",
       "----------\n",
       "T : ndarray\n",
       "    Transpose of the array.\n",
       "data : buffer\n",
       "    The array's elements, in memory.\n",
       "dtype : dtype object\n",
       "    Describes the format of the elements in the array.\n",
       "flags : dict\n",
       "    Dictionary containing information related to memory use, e.g.,\n",
       "    'C_CONTIGUOUS', 'OWNDATA', 'WRITEABLE', etc.\n",
       "flat : numpy.flatiter object\n",
       "    Flattened version of the array as an iterator.  The iterator\n",
       "    allows assignments, e.g., ``x.flat = 3`` (See `ndarray.flat` for\n",
       "    assignment examples; TODO).\n",
       "imag : ndarray\n",
       "    Imaginary part of the array.\n",
       "real : ndarray\n",
       "    Real part of the array.\n",
       "size : int\n",
       "    Number of elements in the array.\n",
       "itemsize : int\n",
       "    The memory use of each array element in bytes.\n",
       "nbytes : int\n",
       "    The total number of bytes required to store the array data,\n",
       "    i.e., ``itemsize * size``.\n",
       "ndim : int\n",
       "    The array's number of dimensions.\n",
       "shape : tuple of ints\n",
       "    Shape of the array.\n",
       "strides : tuple of ints\n",
       "    The step-size required to move from one element to the next in\n",
       "    memory. For example, a contiguous ``(3, 4)`` array of type\n",
       "    ``int16`` in C-order has strides ``(8, 2)``.  This implies that\n",
       "    to move from element to element in memory requires jumps of 2 bytes.\n",
       "    To move from row-to-row, one needs to jump 8 bytes at a time\n",
       "    (``2 * 4``).\n",
       "ctypes : ctypes object\n",
       "    Class containing properties of the array needed for interaction\n",
       "    with ctypes.\n",
       "base : ndarray\n",
       "    If the array is a view into another array, that array is its `base`\n",
       "    (unless that array is also a view).  The `base` array is where the\n",
       "    array data is actually stored.\n",
       "\n",
       "See Also\n",
       "--------\n",
       "array : Construct an array.\n",
       "zeros : Create an array, each element of which is zero.\n",
       "empty : Create an array, but leave its allocated memory unchanged (i.e.,\n",
       "        it contains \"garbage\").\n",
       "dtype : Create a data-type.\n",
       "\n",
       "Notes\n",
       "-----\n",
       "There are two modes of creating an array using ``__new__``:\n",
       "\n",
       "1. If `buffer` is None, then only `shape`, `dtype`, and `order`\n",
       "   are used.\n",
       "2. If `buffer` is an object exposing the buffer interface, then\n",
       "   all keywords are interpreted.\n",
       "\n",
       "No ``__init__`` method is needed because the array is fully initialized\n",
       "after the ``__new__`` method.\n",
       "\n",
       "Examples\n",
       "--------\n",
       "These examples illustrate the low-level `ndarray` constructor.  Refer\n",
       "to the `See Also` section above for easier ways of constructing an\n",
       "ndarray.\n",
       "\n",
       "First mode, `buffer` is None:\n",
       "\n",
       ">>> np.ndarray(shape=(2,2), dtype=float, order='F')\n",
       "array([[ -1.13698227e+002,   4.25087011e-303],\n",
       "       [  2.88528414e-306,   3.27025015e-309]])         #random\n",
       "\n",
       "Second mode:\n",
       "\n",
       ">>> np.ndarray((2,), buffer=np.array([1,2,3]),\n",
       "...            offset=np.int_().itemsize,\n",
       "...            dtype=int) # offset = 1*itemsize, i.e. skip first element\n",
       "array([2, 3])\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dependent variable\n",
    "\n",
    "y = dataset.iloc[:, 1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and testing our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fitting the model to the Naive Bayes algorithm\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "classifier = GaussianNB()\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 67,  50],\n",
       "       [ 20, 113]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = (67+113)/250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.72"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using Support Vector Machine\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier2 = SVC(kernel = 'linear', random_state = 0)\n",
    "classifier2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred2 = classifier2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm2 = confusion_matrix(y_test, y_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[94, 23],\n",
       "       [49, 84]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.712"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc2 = (94+84)/250\n",
    "acc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
